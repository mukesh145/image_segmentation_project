{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--root ROOT] [--overwrite]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/Users/user/Library/Jupyter/runtime/kernel-v38d4bd49bd321a25d84cb6b8ca24320f6ccfe6b31.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "init_cadseg.py\n",
    "Creates a ready-to-use project skeleton for CAD multi-label image segmentation (UNet++/ResNet34, SMP).\n",
    "No heavy code—just structured placeholders, configs, and docs so you can start filling things in.\n",
    "\n",
    "Usage:\n",
    "  python init_cadseg.py --root cadseg        # default\n",
    "  python init_cadseg.py --root myproj --overwrite\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from textwrap import dedent\n",
    "\n",
    "# -----------------------------\n",
    "# Template contents\n",
    "# -----------------------------\n",
    "GITIGNORE = dedent(\"\"\"\n",
    "# Python\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pyo\n",
    "*.pyd\n",
    ".pytest_cache/\n",
    ".venv/\n",
    "env/\n",
    "venv/\n",
    "build/\n",
    "dist/\n",
    "*.egg-info/\n",
    "\n",
    "# Data & runs\n",
    "data/images/\n",
    "data/masks/\n",
    "data/splits/\n",
    "runs/\n",
    "outputs/\n",
    "checkpoints/\n",
    ".wandb/\n",
    "mlruns/\n",
    "\n",
    "# OS / IDE\n",
    ".DS_Store\n",
    "Thumbs.db\n",
    ".idea/\n",
    ".vscode/\n",
    "\"\"\").lstrip()\n",
    "\n",
    "README = dedent(\"\"\"\n",
    "# CADSeg — Multi-label CAD Violation Segmentation\n",
    "\n",
    "This repository is a **template** for training a **multi-label** image segmentation model\n",
    "(one channel per CAD rule violation) on high-resolution CAD drawings using tiling.\n",
    "\n",
    "## Key ideas\n",
    "- **Architecture**: UNet++ with ResNet-34 encoder (ImageNet-pretrained) via `segmentation_models_pytorch`.\n",
    "- **Output**: C channels (one per rule), **sigmoid** activations (multi-label).\n",
    "- **Loss**: Per-class Dice + BCEWithLogits (class-weighted).\n",
    "- **Tiling**: Large canvases → 1024×1024 tiles with ~256 px overlap and weighted stitching.\n",
    "- **Sampling**: Class-balanced batch sampler that prefers tiles with positives.\n",
    "- **Thresholds**: Calibrate per-class thresholds on validation set.\n",
    "\n",
    "## Quick start\n",
    "1) Create a venv and install `requirements.txt`.\n",
    "2) Fill `configs/*.yaml` with your paths/classes.\n",
    "3) Add your data under `data/` (images + masks per rule).\n",
    "4) Implement loaders and loops under `cadseg/` (placeholders provided).\n",
    "5) Train via `cadseg/cli/train.py` (entry point stub provided).\n",
    "\n",
    "> This template intentionally ships **without** heavy code so you can adapt quickly to your setup.\n",
    "\"\"\").lstrip()\n",
    "\n",
    "REQUIREMENTS = dedent(\"\"\"\n",
    "torch>=2.2\n",
    "torchvision>=0.17\n",
    "segmentation-models-pytorch>=0.3.3\n",
    "timm>=1.0.0\n",
    "albumentations>=1.3.1\n",
    "opencv-python-headless>=4.10.0.84\n",
    "numpy>=1.26\n",
    "scikit-image>=0.24\n",
    "scikit-learn>=1.4\n",
    "pyyaml>=6.0.1\n",
    "tqdm>=4.66\n",
    "rich>=13.7\n",
    "matplotlib>=3.8\n",
    "# optional\n",
    "mlflow>=2.13\n",
    "einops>=0.8\n",
    "torchmetrics>=1.4\n",
    "onnx>=1.16\n",
    "onnxruntime>=1.18\n",
    "pytest>=8.2\n",
    "loguru>=0.7\n",
    "\"\"\").strip()\n",
    "\n",
    "# --- Configs (starter templates) ---\n",
    "DATASET_YAML = dedent(\"\"\"\n",
    "# configs/dataset.yaml\n",
    "root: ./data\n",
    "images_dir: images\n",
    "masks_dir: masks\n",
    "classes:             # one channel per rule (order defines channel index)\n",
    "  - rule_00_arrow_not_touching\n",
    "  - rule_01_text_overlap_line\n",
    "  - rule_02_missing_dimension\n",
    "C: 3                  # must match number of classes\n",
    "tile_size: 1024\n",
    "tile_overlap: 256\n",
    "num_workers: 4\n",
    "seed: 42\n",
    "folds: 1              # or use GroupKFold later\n",
    "min_positive_area: 64 # px^2; used for positive tile mining\n",
    "\"\"\").lstrip()\n",
    "\n",
    "MODEL_YAML = dedent(\"\"\"\n",
    "# configs/model.yaml\n",
    "arch: unet++            # UNet++ (nested U-Net)\n",
    "encoder: resnet34\n",
    "encoder_weights: imagenet\n",
    "in_channels: 3\n",
    "num_classes: 3          # keep in sync with dataset.yaml:C\n",
    "dropout: 0.1\n",
    "use_edge_aux: false     # optional edge-aware aux head (Sobel)\n",
    "\"\"\").lstrip()\n",
    "\n",
    "TRAIN_YAML = dedent(\"\"\"\n",
    "# configs/train.yaml\n",
    "epochs: 40\n",
    "batch_size: 4\n",
    "optimizer: adamw\n",
    "lr: 3.0e-4\n",
    "weight_decay: 1.0e-4\n",
    "sched: onecycle          # onecycle | cosine | reduce_on_plateau\n",
    "amp: true\n",
    "grad_clip: 1.0\n",
    "freeze_encoder_stages: [0, 1]  # warmup freeze (stem + stage1)\n",
    "unfreeze_at_epoch: 2\n",
    "loss: dice_bce           # dice_bce | dice_focal | tversky | dice_ce\n",
    "focal_gamma: 2.0\n",
    "tversky_alpha: 0.7\n",
    "tversky_beta: 0.3\n",
    "class_weights: null      # e.g., [1.0, 1.4, 1.8] (inverse sqrt freq)\n",
    "save_metric: macro_mIoU  # checkpoint by this metric\n",
    "early_stop_patience: 8\n",
    "\"\"\").lstrip()\n",
    "\n",
    "AUG_YAML = dedent(\"\"\"\n",
    "# configs/aug.yaml\n",
    "train:\n",
    "  flip: true\n",
    "  rotate90: true\n",
    "  scale_jitter: 0.1          # ±10%\n",
    "  brightness_contrast: 0.1\n",
    "  gaussian_noise_std: 0.01\n",
    "  gaussian_blur_ksize: 3     # set 0 to disable\n",
    "  tiny_affine_px: 2          # translate ≤2px; no elastic to avoid bending lines\n",
    "valid:\n",
    "  resize: null               # or \"fit_long_side: 2048\"\n",
    "  center_crop: null\n",
    "infer:\n",
    "  pad_to_tile: true\n",
    "\"\"\").lstrip()\n",
    "\n",
    "INFER_YAML = dedent(\"\"\"\n",
    "# configs/infer.yaml\n",
    "tta: [hflip, vflip]         # optional\n",
    "merge: mean                 # mean | gmean | max\n",
    "tile_size: 1024\n",
    "tile_overlap: 256\n",
    "min_component_area:         # optional per-class small blob removal\n",
    "  - 32\n",
    "  - 32\n",
    "  - 32\n",
    "thresholds_file: configs/thresholds.json\n",
    "\"\"\").lstrip()\n",
    "\n",
    "THRESHOLDS_JSON = json.dumps({\n",
    "    \"rule_00_arrow_not_touching\": 0.50,\n",
    "    \"rule_01_text_overlap_line\": 0.50,\n",
    "    \"rule_02_missing_dimension\": 0.50\n",
    "}, indent=2)\n",
    "\n",
    "CLASSES_JSON = json.dumps({\n",
    "    \"classes\": [\n",
    "        {\"index\": 0, \"name\": \"rule_00_arrow_not_touching\"},\n",
    "        {\"index\": 1, \"name\": \"rule_01_text_overlap_line\"},\n",
    "        {\"index\": 2, \"name\": \"rule_02_missing_dimension\"}\n",
    "    ]\n",
    "}, indent=2)\n",
    "\n",
    "# Minimal placeholders for package modules (light docstrings, no logic)\n",
    "PY_PLACEHOLDER = dedent('''\\\n",
    "\"\"\"\n",
    "Placeholder module. Implement functions/classes as needed.\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "CONFIG_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Config loaders and typed dataclasses for dataset/model/train/aug/infer.\n",
    "Fill with pydantic or dataclasses + YAML parsing.\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "DATASETS_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Dataset stubs:\n",
    "- CADSegDataset: full images and masks (multi-label).\n",
    "- TiledDataset: tile view over large canvases (with overlap).\n",
    "- InferenceDataset: images only, for inference-time tiling.\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "TILING_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Tiling utilities:\n",
    "- tile_image()\n",
    "- stitch_probs() with weighted (e.g., Hann) blending\n",
    "- valid-window masks\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "SAMPLING_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Samplers:\n",
    "- ClassBalancedBatchSampler\n",
    "- PositiveTileSampler\n",
    "- WeightedRandomSampler for rare classes\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "TRANSFORMS_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Albumentations pipelines for train/valid/infer (CAD-safe).\n",
    "Ensure mask and image transforms stay synchronized.\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "MASKS_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Mask IO and morphology utilities:\n",
    "- load/save binary masks\n",
    "- multi-label stacking (C channels)\n",
    "- small-component removal, dilation/erosion (very mild)\n",
    "- optional RLE helpers\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "COLLATE_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Custom collate functions for tile batches, dtype control, channel stacking.\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "BUILDER_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Model builder:\n",
    "- UNet++ with ResNet-34 encoder (ImageNet)\n",
    "- num_classes = C (multi-label, sigmoid used only at eval/metrics)\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "LOSSES_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Losses:\n",
    "- Dice, BCEWithLogits, Focal, Tversky\n",
    "- Per-class weighting wrappers and combos\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "METRICS_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Metrics:\n",
    "- Per-class IoU/Dice, macro/micro averages\n",
    "- Optional PR/ROC curve helpers (for calibration)\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "POSTPROCESS_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Post-processing:\n",
    "- Per-class thresholds\n",
    "- Small-blob removal\n",
    "- Edge sharpening (optional)\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "EDGE_AUX_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Edge auxiliary head (optional):\n",
    "- Sobel-based pseudo-targets for boundary sharpening\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "TRAIN_LOOP_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Training loop skeleton:\n",
    "- AMP, grad clip, checkpointing, early stopping\n",
    "- Encoder freeze/unfreeze schedule\n",
    "- Class-balanced sampling\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "EVAL_LOOP_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Validation/Test loop skeleton:\n",
    "- Full-image evaluation via tiling + stitching\n",
    "- Per-class metrics aggregation and reporting\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "INFER_LOOP_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Inference loop skeleton:\n",
    "- Folder or single image inference\n",
    "- TTA and tile stitching\n",
    "- Writes masks/overlays\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "OPTIMIZER_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Optimizer & scheduler builder:\n",
    "- AdamW, OneCycle / Cosine / ReduceLROnPlateau\n",
    "- Discriminative LR (encoder vs decoder)\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "HOOKS_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Callbacks/Hooks:\n",
    "- Logging, LR finder, threshold calibration\n",
    "- EMA (optional)\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "LOGGING_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Logging utilities using rich/loguru + tqdm progress.\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "SEED_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Seeding utilities for reproducibility (numpy, torch, albumentations).\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "CKPT_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Checkpoint helpers: save/load best model, resume, TorchScript/ONNX export helpers.\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "DIST_PY = dedent('''\\\n",
    "\"\"\"\n",
    "DDP launcher/init (optional). Keep simple unless multi-GPU is required.\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "VIZ_PY = dedent('''\\\n",
    "\"\"\"\n",
    "Quick visualizers for tiles, predictions, overlays, confusion matrices.\n",
    "\"\"\"\n",
    "''')\n",
    "\n",
    "# CLI placeholders\n",
    "PREPARE_DATASET_PY = dedent('''\\\n",
    "\"\"\"\n",
    "CLI: prepare_dataset.py\n",
    "- Scan data/, verify masks, compute class stats, build splits (GroupKFold by drawing).\n",
    "\"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"prepare_dataset: stub\")\n",
    "''')\n",
    "\n",
    "TRAIN_PY = dedent('''\\\n",
    "\"\"\"\n",
    "CLI: train.py\n",
    "- Load configs, build dataloaders/model, run training loop.\n",
    "\"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"train: stub\")\n",
    "''')\n",
    "\n",
    "VALIDATE_PY = dedent('''\\\n",
    "\"\"\"\n",
    "CLI: validate.py\n",
    "- Offline evaluation on valid/test; outputs per-class metrics.\n",
    "\"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"validate: stub\")\n",
    "''')\n",
    "\n",
    "CALIBRATE_PY = dedent('''\\\n",
    "\"\"\"\n",
    "CLI: calibrate.py\n",
    "- Sweep thresholds per class to maximize F1/IoU, save to thresholds.json.\n",
    "\"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"calibrate: stub\")\n",
    "''')\n",
    "\n",
    "INFER_PY = dedent('''\\\n",
    "\"\"\"\n",
    "CLI: infer.py\n",
    "- Batch inference → masks/overlays; optional polygon export.\n",
    "\"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"infer: stub\")\n",
    "''')\n",
    "\n",
    "EXPORT_PY = dedent('''\\\n",
    "\"\"\"\n",
    "CLI: export.py\n",
    "- Export to TorchScript/ONNX; optional INT8 PTQ (onnxruntime).\n",
    "\"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"export: stub\")\n",
    "''')\n",
    "\n",
    "# Scripts\n",
    "VIS_SAMPLES_PY = dedent('''\\\n",
    "\"\"\"scripts/visualize_samples.py — quick grids of (image, GT, aug preview).\"\"\"\n",
    "''')\n",
    "\n",
    "SANITY_MASKS_PY = dedent('''\\\n",
    "\"\"\"scripts/sanity_check_masks.py — ensure masks align with images, values in {0,1}.\"\"\"\n",
    "''')\n",
    "\n",
    "PROFILE_INFER_PY = dedent('''\\\n",
    "\"\"\"scripts/profile_inference.py — measure throughput/latency for different tile sizes/overlaps.\"\"\"\n",
    "''')\n",
    "\n",
    "# Tests\n",
    "TEST_TILING = dedent('''\\\n",
    "def test_tiling_placeholder():\n",
    "    assert True\n",
    "''')\n",
    "\n",
    "TEST_TRANSFORMS = dedent('''\\\n",
    "def test_transforms_placeholder():\n",
    "    assert True\n",
    "''')\n",
    "\n",
    "TEST_METRICS = dedent('''\\\n",
    "def test_metrics_placeholder():\n",
    "    assert True\n",
    "''')\n",
    "\n",
    "# -----------------------------\n",
    "# Files to create\n",
    "# -----------------------------\n",
    "FILES = {\n",
    "    \".gitignore\": GITIGNORE,\n",
    "    \"README.md\": README,\n",
    "    \"requirements.txt\": REQUIREMENTS,\n",
    "\n",
    "    # configs\n",
    "    \"configs/dataset.yaml\": DATASET_YAML,\n",
    "    \"configs/model.yaml\": MODEL_YAML,\n",
    "    \"configs/train.yaml\": TRAIN_YAML,\n",
    "    \"configs/aug.yaml\": AUG_YAML,\n",
    "    \"configs/infer.yaml\": INFER_YAML,\n",
    "    \"configs/thresholds.json\": THRESHOLDS_JSON,\n",
    "\n",
    "    # data\n",
    "    \"data/meta/classes.json\": CLASSES_JSON,\n",
    "    \"data/splits/train.txt\": \"\",\n",
    "    \"data/splits/valid.txt\": \"\",\n",
    "    \"data/splits/test.txt\": \"\",\n",
    "    \"data/masks/.keep\": \"\",\n",
    "    \"data/masks/rule_00/.keep\": \"\",\n",
    "    \"data/masks/rule_01/.keep\": \"\",\n",
    "    \"data/masks/rule_02/.keep\": \"\",\n",
    "    \"data/images/.keep\": \"\",\n",
    "\n",
    "    # package roots\n",
    "    \"cadseg/__init__.py\": \"\",\n",
    "    \"cadseg/config.py\": CONFIG_PY,\n",
    "\n",
    "    # dataio\n",
    "    \"cadseg/dataio/__init__.py\": \"\",\n",
    "    \"cadseg/dataio/datasets.py\": DATASETS_PY,\n",
    "    \"cadseg/dataio/tiling.py\": TILING_PY,\n",
    "    \"cadseg/dataio/sampling.py\": SAMPLING_PY,\n",
    "    \"cadseg/dataio/transforms.py\": TRANSFORMS_PY,\n",
    "    \"cadseg/dataio/masks.py\": MASKS_PY,\n",
    "    \"cadseg/dataio/collate.py\": COLLATE_PY,\n",
    "\n",
    "    # models\n",
    "    \"cadseg/models/__init__.py\": \"\",\n",
    "    \"cadseg/models/builder.py\": BUILDER_PY,\n",
    "    \"cadseg/models/losses.py\": LOSSES_PY,\n",
    "    \"cadseg/models/metrics.py\": METRICS_PY,\n",
    "    \"cadseg/models/postprocess.py\": POSTPROCESS_PY,\n",
    "    \"cadseg/models/edge_aux.py\": EDGE_AUX_PY,\n",
    "\n",
    "    # engine\n",
    "    \"cadseg/engine/__init__.py\": \"\",\n",
    "    \"cadseg/engine/train_loop.py\": TRAIN_LOOP_PY,\n",
    "    \"cadseg/engine/eval_loop.py\": EVAL_LOOP_PY,\n",
    "    \"cadseg/engine/infer_loop.py\": INFER_LOOP_PY,\n",
    "    \"cadseg/engine/optimizer.py\": OPTIMIZER_PY,\n",
    "    \"cadseg/engine/hooks.py\": HOOKS_PY,\n",
    "\n",
    "    # utils\n",
    "    \"cadseg/utils/__init__.py\": \"\",\n",
    "    \"cadseg/utils/logging.py\": LOGGING_PY,\n",
    "    \"cadseg/utils/seed.py\": SEED_PY,\n",
    "    \"cadseg/utils/ckpt.py\": CKPT_PY,\n",
    "    \"cadseg/utils/distributed.py\": DIST_PY,\n",
    "    \"cadseg/utils/viz.py\": VIZ_PY,\n",
    "\n",
    "    # CLI\n",
    "    \"cadseg/cli/__init__.py\": \"\",\n",
    "    \"cadseg/cli/prepare_dataset.py\": PREPARE_DATASET_PY,\n",
    "    \"cadseg/cli/train.py\": TRAIN_PY,\n",
    "    \"cadseg/cli/validate.py\": VALIDATE_PY,\n",
    "    \"cadseg/cli/calibrate.py\": CALIBRATE_PY,\n",
    "    \"cadseg/cli/infer.py\": INFER_PY,\n",
    "    \"cadseg/cli/export.py\": EXPORT_PY,\n",
    "\n",
    "    # scripts\n",
    "    \"scripts/visualize_samples.py\": VIS_SAMPLES_PY,\n",
    "    \"scripts/sanity_check_masks.py\": SANITY_MASKS_PY,\n",
    "    \"scripts/profile_inference.py\": PROFILE_INFER_PY,\n",
    "\n",
    "    # tests\n",
    "    \"tests/test_tiling.py\": TEST_TILING,\n",
    "    \"tests/test_transforms.py\": TEST_TRANSFORMS,\n",
    "    \"tests/test_metrics.py\": TEST_METRICS,\n",
    "\n",
    "    # notebooks\n",
    "    \"notebooks/.keep\": \"\",\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def write_file(base: Path, rel: str, content: str, overwrite: bool = False):\n",
    "    path = base / rel\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if path.exists() and not overwrite:\n",
    "        print(f\"SKIP  {rel} (exists)\")\n",
    "        return\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    print(f\"WRITE {rel}\")\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--root\", type=str, default=\"cadseg\", help=\"Project root directory to create.\")\n",
    "    ap.add_argument(\"--overwrite\", action=\"store_true\", help=\"Overwrite existing files.\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    root = Path(args.root).resolve()\n",
    "    root.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Creating project at: {root}\")\n",
    "\n",
    "    for rel, content in FILES.items():\n",
    "        write_file(root, rel, content, overwrite=args.overwrite)\n",
    "\n",
    "    print(\"\\nDone. Next steps:\")\n",
    "    print(f\"  1) cd {root}\")\n",
    "    print(\"  2) python -m venv .venv && source .venv/bin/activate   # (Windows: .venv\\\\Scripts\\\\activate)\")\n",
    "    print(\"  3) pip install -r requirements.txt\")\n",
    "    print(\"  4) Edit configs/*.yaml (paths/classes).\")\n",
    "    print(\"  5) Start filling modules in cadseg/, then run: python -m cadseg.cli.train\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
